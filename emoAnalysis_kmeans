#-*-coding:utf-8 -*-
'''
Created on 18-8-2
@author: minghui_J
lat、lon、timed的聚类,分三类后情绪的分布情况是晚上positive、中午neutal、早晨negative
方法是用emo_score_average
'''
import pymysql
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
def query_all(cur, query):
    cur.execute(query)
    return cur.fetchall()

def GetDist(lon_temp_ZP, lon_temp_P2_ZP, lon_temp_P3, lat_temp_ZP, lat_temp_P2_ZP, lat_temp_P3, lon_ZP, lon_P2_ZP, lon_P3, lat_ZP, lat_P2_ZP, lat_P3):

    # The Company used below is "KiloMeter"
    dist_P1_lon_sq = ((lon_temp_ZP - lon_ZP) * 111)**2
    dist_P2_lon_sq = ((lon_temp_P2_ZP - lon_P2_ZP) * 1.85)**2
    dist_P3_lon_sq = ((lon_temp_P3 - lon_P3) * 0.0309)**2

    dist_P1_lat_sq = ((lat_temp_ZP - lat_ZP) * 111) ** 2
    dist_P2_lat_sq = ((lat_temp_P2_ZP - lat_P2_ZP) * 1.85) ** 2
    dist_P3_lat_sq = ((lat_temp_P3 - lat_P3) * 0.0309) ** 2

    dis_sum = dist_P1_lon_sq + dist_P2_lon_sq + dist_P3_lon_sq + dist_P1_lat_sq + dist_P2_lat_sq + dist_P3_lat_sq

    return dis_sum

def Transfer2TimeType(lon_temp, lat_temp):

    # Part1 Used
    lon_temp_ZP = int(lon_temp) # Get The Main Number Part
    lat_temp_ZP = int(lat_temp) # Get The Main Number Part

    lon_temp_minP = (lon_temp - lon_temp_ZP) * 60
    lat_temp_minP = (lat_temp - lat_temp_ZP) * 60

    # Big letter 'P' refers to the Word "Part"
    # Part2 Used
    lon_P2_ZP = int(lon_temp_minP)
    lat_P2_ZP = int(lat_temp_minP)

    lon_P2_minP = lon_temp_minP - lon_P2_ZP
    lat_P2_minP = lat_temp_minP - lat_P2_ZP

    # Part3 Used
    lon_P3 = lon_P2_minP * 60
    lat_P3 = lat_P2_minP * 60

    return lon_temp_ZP, lon_P2_ZP, lon_P3, lat_temp_ZP, lat_P2_ZP, lat_P3

def getData(data_lat,data_lon,data_time,data_emo):
    conn = pymysql.connect(host='localhost', port=3306, user='root', passwd='JMHjmh1998', db='weibodata', charset='utf8')
    cur=conn.cursor()
    query = 'select lat,lon,score,time,emotion_label from d_new_textEmotion where emotion_label!="None"'
    arr = query_all(cur,query)
    cur.close()
    conn.close()
    for key in arr:
        time=(float(str(key[3]).split(':')[0])) + (float(str(key[3]).split(':')[1]) / 60) + (
                float(str(key[3]).split(':')[2]) / 3600)
        if key[4]=='0':
            data_lat.append(float(key[0]))
            data_lon.append(float(key[1]))
            data_time.append(time)
            data_emo.append(1-float(key[2]))
        if key[4]=='1':
            data_lat.append(float(key[0]))
            data_lon.append(float(key[1]))
            data_time.append(time)
            data_emo.append(float(0.5))
        if key[4]=='2':
            data_lat.append(float(key[0]))
            data_lon.append(float(key[1]))
            data_time.append(time)
            data_emo.append(float(key[2]))
    return (data_lat,data_lon,data_time,data_emo)

def normalization(lat,lon,time):
    normal_lat=[]
    normal_lon=[]
    normal_time=[]
    for i in range(len(lat)):
        max_lat=max(lat)
        min_lat=min(lat)
        normal_lat.append((float(lat[i]-min_lat))/(float(max_lat-min_lat)))
        max_lon=max(lon)
        min_lon=min(lon)
        normal_lon.append((float(lon[i]-min_lon))/(float(max_lon-min_lon)))
        max_time=max(time)
        min_time=min(time)
        normal_time.append((float(time[i]-min_time))/(float(max_time-min_time)))
    return normal_lat,normal_lon,normal_time

def useKmeans(lat,lon,time,k):
    data=np.array(list(zip(lat,lon,time))).reshape(len(lat),3)
    estimator = KMeans(n_clusters=k)
    kmeans=estimator.fit(data)
    labels = kmeans.labels_
    center = kmeans.cluster_centers_
    print "center:"
    print center
    return labels

def groupList(labels,lat,lon,time,emo,k):
    lat_result = []
    lon_result = []
    time_result = []
    emo_score= []
    for i in range(k):
        lat_result.append([])
        lon_result.append([])
        time_result.append([])
        emo_score.append([])
    for i,l in enumerate(labels):
        lat_result[l].append(lat[i])
        lon_result[l].append(lon[i])
        time_result[l].append(time[i])
        emo_score[l].append(emo[i])
    return lat_result,lon_result,time_result,emo_score

def drawPic(lat_result,lon_result,time_result):
    ax = plt.subplot(111, projection='3d')
    plot1 = ax.scatter(np.array(lat_result[0]), np.array(lon_result[0]), np.array(time_result[0]), color='r',
                       marker='x', alpha=0.5)
    plot2 = ax.scatter(np.array(lat_result[1]), np.array(lon_result[1]), np.array(time_result[1]), color='b',
                       marker='o', alpha=0.5)
    plot3 = ax.scatter(np.array(lat_result[2]), np.array(lon_result[2]), np.array(time_result[2]), color='g',
                       marker='*', alpha=0.5)
    plt.legend(plot1, plot2, plot3,labels=['A', 'B', 'C'])
    ax.set_zlabel('time')
    ax.set_ylabel('lon')
    ax.set_xlabel('lat')
    plt.show()

def getEmoScore(emo_score):
    emo_average_score = 0
    for i in range(len(emo_score)):
        for key in emo_score[i]:
            emo_average_score += float(key)
        emo_average_score /= len(emo_score[i])
        print "%d emo_average_score" % i, " ", emo_average_score
        emo_average_score = 0

if __name__=='__main__':
    lat=[]
    lon=[]
    time=[]
    emo=[]
    getData(lat,lon,time,emo)
    normal_lat,normal_lon,normal_time=normalization(lat,lon,time)
    labels=useKmeans(normal_lat,normal_lon,normal_time,k=3)
    lat_result,lon_result,time_result,emo_score=groupList(labels,lat,lon,time,emo,k=3)
    getEmoScore(emo_score)
    drawPic(lat_result,lon_result,time_result)
